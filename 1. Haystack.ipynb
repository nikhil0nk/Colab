{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Haystack.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCHbzyNHylno"
      },
      "source": [
        "!nvidia-smi\n",
        "!pip install git+https://github.com/LIAAD/yake\n",
        "!pip install grpcio-tools==1.34.1\n",
        "!pip install --upgrade git+https://github.com/deepset-ai/haystack.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie6YTpxYoyPo"
      },
      "source": [
        "#from haystack.preprocessor.cleaning import clean_wiki_text\n",
        "#from haystack.preprocessor.utils import convert_files_to_dicts, fetch_archive_from_http\n",
        "#from haystack.reader.transformers import TransformersReader\n",
        "from haystack.utils import print_answers\n",
        "from pprint import pprint\n",
        "from haystack.generator.transformers import Seq2SeqGenerator\n",
        "\n",
        "# Base Reader\n",
        "from haystack.pipeline import ExtractiveQAPipeline\n",
        "from haystack.reader.farm import FARMReader\n",
        "reader = FARMReader(\"deepset/roberta-base-squad2\", use_gpu=True)\n",
        "\n",
        "#FAISS\n",
        "from haystack.document_store import FAISSDocumentStore\n",
        "document_store = FAISSDocumentStore(faiss_index_factory_str=\"Flat\", return_embedding=True)\n",
        "\n",
        "#Classifier and Summarizer\n",
        "from haystack.document_classifier import TransformersDocumentClassifier\n",
        "from haystack import Pipeline\n",
        "from haystack.summarizer import TransformersSummarizer\n",
        "from haystack.pipeline import SearchSummarizationPipeline\n",
        "doc_classifier_model = 'textattack/bert-base-uncased-imdb'\n",
        "doc_classifier = TransformersDocumentClassifier(model_name_or_path=doc_classifier_model)\n",
        "\n",
        "#QA Generator\n",
        "from haystack.pipelines import QuestionGenerationPipeline, RetrieverQuestionGenerationPipeline\n",
        "from haystack.pipelines import QuestionAnswerGenerationPipeline\n",
        "from haystack.question_generator import QuestionGenerator # Initialize Question Generator\n",
        "question_generator = QuestionGenerator(use_gpu=True) \n",
        "\n",
        "# LFQA Generator\n",
        "from haystack.pipeline import GenerativeQAPipeline\n",
        "generator = Seq2SeqGenerator(model_name_or_path=\"yjernite/bart_eli5\")\n",
        "\n",
        "# Yake\n",
        "import yake"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WiHw1D7L5qh"
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "reviews_text = \"\"\n",
        "doc_list = []\n",
        "with open('B092YHJGMN.json') as json_file:\n",
        "  data = json.load(json_file)\n",
        "  for i in data['reviews']:\n",
        "    localdict = {}\n",
        "    localdict2 = {}\n",
        "    reviews_text += str(i['reviewText'])\n",
        "    localdict2[\"name\"] = i['reviewerName']\n",
        "    localdict[\"content\"] = i['reviewText']\n",
        "    localdict[\"meta\"] = localdict2\n",
        "    doc_list.append(localdict)\n",
        "\n",
        "n = len(doc_list)\n",
        "print(\"Total Reviews: \", n)\n",
        "reviews_text = reviews_text.replace('\"', '')\n",
        "document_store.write_documents(doc_list)\n",
        "\n",
        "#Load DPR\n",
        "from haystack.retriever.dense import DensePassageRetriever\n",
        "retriever = DensePassageRetriever(document_store=document_store,\n",
        "                                  query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
        "                                  passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
        "                                  max_seq_len_query=64,\n",
        "                                  max_seq_len_passage=256,\n",
        "                                  batch_size=16,\n",
        "                                  use_gpu=True,\n",
        "                                  embed_title=True,\n",
        "                                  use_fast_tokenizers=True)\n",
        "# Important: \n",
        "# Now that after we have the DPR initialized, we need to call update_embeddings() to iterate over all\n",
        "# previously indexed documents and update their embedding representation. \n",
        "# While this can be a time consuming operation (depending on corpus size), it only needs to be done once. \n",
        "# At query time, we only need to embed the query and compare it the existing doc embeddings which is very fast.\n",
        "document_store.update_embeddings(retriever)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjzMQBklvVXU"
      },
      "source": [
        "kw_list = []\n",
        "\n",
        "kw_extractor = yake.KeywordExtractor(lan=\"en\", n=3, dedupLim=0.2, dedupFunc='seqm', windowsSize=1, top=30)\n",
        "keywords = kw_extractor.extract_keywords(reviews_text)\n",
        "\n",
        "for keyword in keywords:\n",
        "  kw_list.append(keyword[0])\n",
        "\n",
        "\n",
        "print(kw_list)\n",
        "ques = \"How long is the battery life?\" #\"Can i play wow?\" \"Can i upgrade up to 32gb of ram?\"\n",
        "kw_old = \"battery life\" #\"play wow\" #\"upgrade ram\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGPs1RbptIZl"
      },
      "source": [
        "#QA Generator\n",
        "\n",
        "# The most basic version of a question generator pipeline takes a document as input and outputs generated\n",
        "# questions which the the document can answer.\n",
        "qg_pipeline = QuestionGenerationPipeline(question_generator)\n",
        "for document in document_store:\n",
        "  result_qg = qg_pipeline.run(documents=[document])\n",
        "  print(result_qg['generated_questions'][0]['questions']) \n",
        "\n",
        "output_kw = []\n",
        "output_QAgen = []\n",
        "# This pipeline takes a query as input. It retrieves relevant documents and then generates questions based on these.\n",
        "rqg_pipeline = RetrieverQuestionGenerationPipeline(retriever, question_generator)\n",
        "for kw in kw_list:\n",
        "  print(kw)\n",
        "  result_rqg = rqg_pipeline.run(query=kw)\n",
        "  for i in range(len(result_rqg['generated_questions'][0]['questions'])):\n",
        "    pprint(result_rqg['generated_questions'][0]['questions'][i])\n",
        "    output_kw.append(kw)\n",
        "    output_QAgen.append(result_rqg['generated_questions'][0]['questions'][i])\n",
        "\n",
        "# This pipeline takes a document as input, generates questions on it, and attempts to answer these questions using\n",
        "# a Reader model\n",
        "qag_pipeline = QuestionAnswerGenerationPipeline(question_generator, reader)\n",
        "for document in document_store:\n",
        "  result_qag = qag_pipeline.run(documents=[document])\n",
        "  pprint(result_qag['results'])\n",
        "  dict_keys(['results', 'documents', 'query_doc_list', 'root_node', 'params', 'node_id'])\n",
        "\n",
        "# LFQA - GenerativeQAPipeline combines a retriever and a reader/generator to answer our questions.\n",
        "gqa_pipeline = GenerativeQAPipeline(generator, retriever)\n",
        "result_gqa = gqa_pipeline.run(query=ques, params={\"Retriever\": {\"top_k\": 50}})\n",
        "pprint(result_gqa['answers'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub2PTGBTyVEq"
      },
      "source": [
        "df = pd.DataFrame(output_kw, columns = ['Keywords Generated'])\n",
        "df['Questions Generated'] = output_QAgen\n",
        "df.to_csv(\"QA_Gen.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDN9wjg1AwHQ"
      },
      "source": [
        "#classifer\n",
        "pipeline = Pipeline()\n",
        "pipeline.add_node(component=retriever, name=\"Retriever\", inputs=[\"Query\"])\n",
        "pipeline.add_node(component=doc_classifier, name='Classifier', inputs=['Retriever'])\n",
        "result_classifier = pipeline.run(query=question, params={\"Retriever\": {\"top_k\": 50}})\n",
        "documents = result_classifier['documents']\n",
        "dictsagain = []\n",
        "count = 0\n",
        "classifier_positive = list()\n",
        "for i in [doc.text for doc in documents if doc.meta['classification']['label'] == 'LABEL_1']:\n",
        "  # ‘LABEL_1’ for a positive sentiment, or ‘LABEL_0’ for negative\n",
        "  print(str(count+1) + \") \" + i)\n",
        "  classifier_positive.append(i)\n",
        "  count = count + 1\n",
        "classifier_negative = list()\n",
        "count = 0\n",
        "for i in [doc.text for doc in documents if doc.meta['classification']['label'] == 'LABEL_0']:\n",
        "  print(str(count+1) + \") \" + i)\n",
        "  classifier_negative.append(i)\n",
        "  count = count + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y6948uYDGKO"
      },
      "source": [
        "#summarizer\n",
        "summarizer = TransformersSummarizer(model_name_or_path='t5-large', min_length=10, max_length=300,\n",
        "                                    generate_single_summary=True)\n",
        "pipeline = SearchSummarizationPipeline(retriever=retriever, summarizer=summarizer)\n",
        "result_summarizer = pipeline.run(query=keyword, params={\"Retriever\": {\"top_k\": 50}})\n",
        "sumarizer_result = list()\n",
        "sumarizer_result_context = list()\n",
        "sumarizer_result.append(result_summarizer['documents'][0].text)\n",
        "sumarizer_result_context.append(result_summarizer['documents'][0].meta['context'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu5MnoxbL9_Y"
      },
      "source": [
        "pipe = ExtractiveQAPipeline(reader, retriever)\n",
        "\n",
        "# You can configure how many candidates the reader and retriever shall return\n",
        "# The higher top_k for retriever, the better (but also the slower) your answers.\n",
        "prediction = pipe.run(query=question, params={\"Retriever\": {\"top_k\": 50}, \"Reader\": {\"top_k\": 50}})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFxdrD8Qbk2q"
      },
      "source": [
        "reader_results = list()\n",
        "reader_results_context = list()\n",
        "for answer in prediction['answers']:\n",
        "  print(answer['answer'])\n",
        "  reader_results.append(answer['answer'])\n",
        "  print(answer['context'])\n",
        "  reader_results_context.append(answer['context'])\n",
        "  # Empty row filling\n",
        "  maxlength = max(len(classifier_positive),len(classifier_negative), len(sumarizer_result), \n",
        "                   len(sumarizer_result_context), len(reader_results), len(reader_results_context))\n",
        "  def fillarray(array):\n",
        "    if len(array) is maxlength:\n",
        "      print(\"ok\")\n",
        "    else:\n",
        "      for x in range(len(array),maxlength):\n",
        "        array.append(\"\")\n",
        "  fillarray(classifier_positive)\n",
        "  fillarray(classifier_negative)\n",
        "  fillarray(sumarizer_result)\n",
        "  fillarray(sumarizer_result_context)\n",
        "  fillarray(reader_results)\n",
        "  fillarray(reader_results_context)\n",
        "  \n",
        "dict = {'question' : \"How long is the battery life?\", \n",
        "        'answer_classifier_positive' : classifier_positive, 'answer_classifier_negative' : classifier_negative,\n",
        "        'answer_summarizer': sumarizer_result, 'answer_sumarizer_context': sumarizer_result_context,\n",
        "        'answer_reader' : reader_results, 'answer_reader_context': reader_results_context}\n",
        "df = pd.DataFrame(dict)\n",
        "df.to_csv('Haystack_result.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}